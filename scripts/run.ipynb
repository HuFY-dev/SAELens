{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook with Example Config for Different Models / Hooks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Warning: This notebook is a WIP and may not reflect current valid / optimal hyperparameters.\n",
    "# We are hoping to provide more serious training examples / advice soon."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from sae_lens.training.config import LanguageModelSAERunnerConfig\n",
    "from sae_lens.training.lm_runner import language_model_sae_runner\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = \"mps\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "\n",
    "print(\"Using device:\", device)\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tiny Stories - 1L"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP Out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = LanguageModelSAERunnerConfig(\n",
    "    # Data Generating Function (Model + Training Distibuion)\n",
    "    model_name=\"tiny-stories-1L-21M\",  # our model (more options here: https://neelnanda-io.github.io/TransformerLens/generated/model_properties_table.html)\n",
    "    hook_point=\"blocks.0.hook_mlp_out\",  # A valid hook point (see more details here: https://neelnanda-io.github.io/TransformerLens/generated/demos/Main_Demo.html#Hook-Points)\n",
    "    hook_point_layer=0,  # Only one layer in the model.\n",
    "    d_in=1024,  # the width of the mlp output.\n",
    "    dataset_path=\"apollo-research/roneneldan-TinyStories-tokenizer-gpt2\",  # this is a tokenized language dataset on Huggingface for the Tiny Stories corpus.\n",
    "    is_dataset_tokenized=True,\n",
    "    # SAE Parameters\n",
    "    mse_loss_normalization=None,  # We won't normalize the mse loss,\n",
    "    expansion_factor=16,  # the width of the SAE. Larger will result in better stats but slower training.\n",
    "    b_dec_init_method=\"geometric_median\",  # The geometric median can be used to initialize the decoder weights.\n",
    "    apply_b_dec_to_input=False,  # We won't apply the decoder to the input.\n",
    "    # Training Parameters\n",
    "    lr=0.0008,  # lower the better, we'll go fairly high to speed up the tutorial.\n",
    "    lr_scheduler_name=\"constant\",  # constant learning rate with warmup. Could be better schedules out there.\n",
    "    lr_warm_up_steps=10000,  # this can help avoid too many dead features initially.\n",
    "    l1_coefficient=0.0015,  # will control how sparse the feature activations are\n",
    "    lp_norm=1.0,  # the L1 penalty (and not a Lp for p < 1)\n",
    "    train_batch_size=4096,\n",
    "    context_size=128,  # will control the lenght of the prompts we feed to the model. Larger is better but slower.\n",
    "    # Activation Store Parameters\n",
    "    n_batches_in_buffer=64,  # controls how many activations we store / shuffle.\n",
    "    training_tokens=1_000_000\n",
    "    * 25,  # 100 million tokens is quite a few, but we want to see good stats. Get a coffee, come back.\n",
    "    finetuning_method=\"decoder\",\n",
    "    finetuning_tokens=1_000_000 * 25,\n",
    "    store_batch_size=32,\n",
    "    # Resampling protocol\n",
    "    use_ghost_grads=False,\n",
    "    feature_sampling_window=1000,  # this controls our reporting of feature sparsity stats\n",
    "    dead_feature_window=1000,  # would effect resampling or ghost grads if we were using it.\n",
    "    dead_feature_threshold=1e-4,  # would effect resampling or ghost grads if we were using it.\n",
    "    # WANDB\n",
    "    log_to_wandb=True,  # always use wandb unless you are just testing code.\n",
    "    wandb_project=\"sae_lens_tutorial\",\n",
    "    wandb_log_frequency=10,\n",
    "    # Misc\n",
    "    device=device,\n",
    "    seed=42,\n",
    "    n_checkpoints=0,\n",
    "    checkpoint_path=\"checkpoints\",\n",
    "    dtype=torch.float32,\n",
    ")\n",
    "\n",
    "# look at the next cell to see some instruction for what to do while this is running.\n",
    "sparse_autoencoder_dictionary = language_model_sae_runner(cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPT2 - Small"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Residual Stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run name: 24576-L1-0.008-LR-0.0004-Tokens-2.000e+08\n",
      "n_tokens_per_buffer (millions): 1.048576\n",
      "Lower bound: n_contexts_per_buffer (millions): 0.004096\n",
      "Total training steps: 73242\n",
      "Total wandb updates: 732\n",
      "n_tokens_per_feature_sampling_window (millions): 2621.44\n",
      "n_tokens_per_dead_feature_window (millions): 5242.88\n",
      "We will reset the sparsity calculation 29 times.\n",
      "Number tokens in sparsity calculation window: 1.02e+07\n",
      "Loaded pretrained model gpt2-small into HookedTransformer\n",
      "Moving model to device:  cuda\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dac332c479a44f71b045887557d8c1cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/73 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24eac100654a43faa4137fe53345a742",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/73 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run name: 24576-L1-0.008-LR-0.0004-Tokens-2.000e+08\n",
      "n_tokens_per_buffer (millions): 1.048576\n",
      "Lower bound: n_contexts_per_buffer (millions): 0.004096\n",
      "Total training steps: 73242\n",
      "Total wandb updates: 732\n",
      "n_tokens_per_feature_sampling_window (millions): 2621.44\n",
      "n_tokens_per_dead_feature_window (millions): 5242.88\n",
      "We will reset the sparsity calculation 29 times.\n",
      "Number tokens in sparsity calculation window: 1.02e+07\n",
      "Run name: 24576-L1-0.008-LR-0.0004-Tokens-2.000e+08\n",
      "n_tokens_per_buffer (millions): 1.048576\n",
      "Lower bound: n_contexts_per_buffer (millions): 0.004096\n",
      "Total training steps: 73242\n",
      "Total wandb updates: 732\n",
      "n_tokens_per_feature_sampling_window (millions): 2621.44\n",
      "n_tokens_per_dead_feature_window (millions): 5242.88\n",
      "We will reset the sparsity calculation 29 times.\n",
      "Number tokens in sparsity calculation window: 1.02e+07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mhufy-dev\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/hufy/SAELens/scripts/wandb/run-20240503_123308-dzedmzx1</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/hufy-dev/gpt2_sae_source_model_loss_normalization/runs/dzedmzx1' target=\"_blank\">24576-L1-0.008-LR-0.0004-Tokens-2.000e+08</a></strong> to <a href='https://wandb.ai/hufy-dev/gpt2_sae_source_model_loss_normalization' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/hufy-dev/gpt2_sae_source_model_loss_normalization' target=\"_blank\">https://wandb.ai/hufy-dev/gpt2_sae_source_model_loss_normalization</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/hufy-dev/gpt2_sae_source_model_loss_normalization/runs/dzedmzx1' target=\"_blank\">https://wandb.ai/hufy-dev/gpt2_sae_source_model_loss_normalization/runs/dzedmzx1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Objective value: 46608920.0000:   3%|▎         | 3/100 [00:00<00:04, 22.16it/s]\n",
      "6016| MSE Loss 1.949 | L1 1.374:   8%|▊         | 24637440/300000000 [19:15<3:49:22, 20007.72it/s]"
     ]
    }
   ],
   "source": [
    "cfg = LanguageModelSAERunnerConfig(\n",
    "    # Data Generating Function (Model + Training Distibuion)\n",
    "    model_name=\"gpt2-small\",\n",
    "    hook_point=\"blocks.8.hook_resid_pre\",\n",
    "    hook_point_layer=8,\n",
    "    d_in=768,\n",
    "    dataset_path=\"apollo-research/Skylion007-openwebtext-tokenizer-gpt2\",\n",
    "    is_dataset_tokenized=True,\n",
    "    prepend_bos=True,  # should experiment with turning this off.\n",
    "    # SAE Parameters\n",
    "    expansion_factor=32,  # determines the dimension of the SAE.\n",
    "    b_dec_init_method=\"geometric_median\",  # geometric median is better but slower to get started\n",
    "    apply_b_dec_to_input=False,\n",
    "    # Training Parameters\n",
    "    adam_beta1=0,\n",
    "    adam_beta2=0.999,\n",
    "    lr=0.0004,\n",
    "    l1_coefficient=0.008,\n",
    "    lr_scheduler_name=\"constant\",\n",
    "    train_batch_size=4096,\n",
    "    context_size=256,\n",
    "    lr_warm_up_steps=5000,\n",
    "    # Activation Store Parameters\n",
    "    n_batches_in_buffer=128,\n",
    "    training_tokens=1_000_000 * 200,  # 200M tokens seems doable overnight.\n",
    "    finetuning_method=\"decoder\",\n",
    "    finetuning_tokens=1_000_000 * 100,\n",
    "    store_batch_size=32,\n",
    "    # Resampling protocol\n",
    "    use_ghost_grads=False,\n",
    "    feature_sampling_window=2500,\n",
    "    dead_feature_window=5000,\n",
    "    dead_feature_threshold=1e-8,\n",
    "    # WANDB\n",
    "    log_to_wandb=True,\n",
    "    wandb_project=\"gpt2_sae_source_model_loss_normalization\",\n",
    "    wandb_entity=None,\n",
    "    wandb_log_frequency=100,\n",
    "    # Misc\n",
    "    device=device,\n",
    "    seed=42,\n",
    "    n_checkpoints=5,\n",
    "    checkpoint_path=\"checkpoints\",\n",
    "    dtype=torch.float32,\n",
    ")\n",
    "\n",
    "sparse_autoencoder = language_model_sae_runner(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run name: 24576-L1-0.008-LR-0.002-Tokens-2.000e+08\n",
      "n_tokens_per_buffer (millions): 1.048576\n",
      "Lower bound: n_contexts_per_buffer (millions): 0.004096\n",
      "Total training steps: 73242\n",
      "Total wandb updates: 732\n",
      "n_tokens_per_feature_sampling_window (millions): 2621.44\n",
      "n_tokens_per_dead_feature_window (millions): 5242.88\n",
      "We will reset the sparsity calculation 29 times.\n",
      "Number tokens in sparsity calculation window: 1.02e+07\n",
      "Loaded pretrained model gpt2-small into HookedTransformer\n",
      "Moving model to device:  cuda\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c03a4104638a4881b2a4c4b186929345",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/73 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "393d01bc6beb4d48a81d612987f93e29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/73 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run name: 24576-L1-0.008-LR-0.002-Tokens-2.000e+08\n",
      "n_tokens_per_buffer (millions): 1.048576\n",
      "Lower bound: n_contexts_per_buffer (millions): 0.004096\n",
      "Total training steps: 73242\n",
      "Total wandb updates: 732\n",
      "n_tokens_per_feature_sampling_window (millions): 2621.44\n",
      "n_tokens_per_dead_feature_window (millions): 5242.88\n",
      "We will reset the sparsity calculation 29 times.\n",
      "Number tokens in sparsity calculation window: 1.02e+07\n",
      "Run name: 24576-L1-0.008-LR-0.002-Tokens-2.000e+08\n",
      "n_tokens_per_buffer (millions): 1.048576\n",
      "Lower bound: n_contexts_per_buffer (millions): 0.004096\n",
      "Total training steps: 73242\n",
      "Total wandb updates: 732\n",
      "n_tokens_per_feature_sampling_window (millions): 2621.44\n",
      "n_tokens_per_dead_feature_window (millions): 5242.88\n",
      "We will reset the sparsity calculation 29 times.\n",
      "Number tokens in sparsity calculation window: 1.02e+07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mhufy-dev\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/hufy/SAELens/scripts/wandb/run-20240503_125300-pkzrp2io</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/hufy-dev/gpt2_sae_source_model_loss_normalization/runs/pkzrp2io' target=\"_blank\">24576-L1-0.008-LR-0.002-Tokens-2.000e+08</a></strong> to <a href='https://wandb.ai/hufy-dev/gpt2_sae_source_model_loss_normalization' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/hufy-dev/gpt2_sae_source_model_loss_normalization' target=\"_blank\">https://wandb.ai/hufy-dev/gpt2_sae_source_model_loss_normalization</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/hufy-dev/gpt2_sae_source_model_loss_normalization/runs/pkzrp2io' target=\"_blank\">https://wandb.ai/hufy-dev/gpt2_sae_source_model_loss_normalization/runs/pkzrp2io</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Objective value: 46445848.0000:   2%|▏         | 2/100 [00:00<00:05, 19.52it/s]\n",
      "6983| MSE Loss 0.535 | L1 0.270:  10%|▉         | 28602368/300000000 [28:38<1:42:36, 44081.61it/s]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 50\u001b[0m\n\u001b[1;32m      1\u001b[0m cfg \u001b[38;5;241m=\u001b[39m LanguageModelSAERunnerConfig(\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;66;03m# Data Generating Function (Model + Training Distibuion)\u001b[39;00m\n\u001b[1;32m      3\u001b[0m     model_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt2-small\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     47\u001b[0m     collect_source_model_loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     48\u001b[0m )\n\u001b[0;32m---> 50\u001b[0m sparse_autoencoder \u001b[38;5;241m=\u001b[39m \u001b[43mlanguage_model_sae_runner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/SAELens/sae_lens/training/lm_runner.py:34\u001b[0m, in \u001b[0;36mlanguage_model_sae_runner\u001b[0;34m(cfg)\u001b[0m\n\u001b[1;32m     31\u001b[0m     wandb\u001b[38;5;241m.\u001b[39minit(project\u001b[38;5;241m=\u001b[39mcfg\u001b[38;5;241m.\u001b[39mwandb_project, config\u001b[38;5;241m=\u001b[39mcast(Any, cfg), name\u001b[38;5;241m=\u001b[39mcfg\u001b[38;5;241m.\u001b[39mrun_name)\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# train SAE\u001b[39;00m\n\u001b[0;32m---> 34\u001b[0m sparse_autoencoder \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_sae_on_language_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m    \u001b[49m\u001b[43msparse_autoencoder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m    \u001b[49m\u001b[43mactivations_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_checkpoints\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_checkpoints\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_batch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeature_sampling_window\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeature_sampling_window\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdead_feature_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdead_feature_threshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_wandb\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_to_wandb\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwandb_log_frequency\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwandb_log_frequency\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cfg\u001b[38;5;241m.\u001b[39mlog_to_wandb:\n\u001b[1;32m     47\u001b[0m     wandb\u001b[38;5;241m.\u001b[39mfinish()\n",
      "File \u001b[0;32m~/SAELens/sae_lens/training/train_sae_on_language_model.py:93\u001b[0m, in \u001b[0;36mtrain_sae_on_language_model\u001b[0;34m(model, sae_group, activation_store, batch_size, n_checkpoints, feature_sampling_window, dead_feature_threshold, use_wandb, wandb_log_frequency)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_sae_on_language_model\u001b[39m(\n\u001b[1;32m     80\u001b[0m     model: HookedRootModule,\n\u001b[1;32m     81\u001b[0m     sae_group: SparseAutoencoderDictionary,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     88\u001b[0m     wandb_log_frequency: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m50\u001b[39m,\n\u001b[1;32m     89\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m SparseAutoencoderDictionary:\n\u001b[1;32m     90\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;124;03m    @deprecated Use `train_sae_group_on_language_model` instead. This method is kept for backward compatibility.\u001b[39;00m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 93\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrain_sae_group_on_language_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     95\u001b[0m \u001b[43m        \u001b[49m\u001b[43msae_group\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[43m        \u001b[49m\u001b[43mactivation_store\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_checkpoints\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfeature_sampling_window\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    100\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_wandb\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    101\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwandb_log_frequency\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    102\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msae_group\n",
      "File \u001b[0;32m~/SAELens/sae_lens/training/train_sae_on_language_model.py:160\u001b[0m, in \u001b[0;36mtrain_sae_group_on_language_model\u001b[0;34m(model, sae_group, activation_store, batch_size, n_checkpoints, feature_sampling_window, use_wandb, wandb_log_frequency)\u001b[0m\n\u001b[1;32m    158\u001b[0m ctx \u001b[38;5;241m=\u001b[39m train_contexts[name]\n\u001b[1;32m    159\u001b[0m wandb_suffix \u001b[38;5;241m=\u001b[39m _wandb_log_suffix(sae_group\u001b[38;5;241m.\u001b[39mcfg, sparse_autoencoder\u001b[38;5;241m.\u001b[39mcfg)\n\u001b[0;32m--> 160\u001b[0m step_output \u001b[38;5;241m=\u001b[39m \u001b[43m_train_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m    \u001b[49m\u001b[43msparse_autoencoder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msparse_autoencoder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlayer_acts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer_acts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[43m    \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeature_sampling_window\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_sampling_window\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_wandb\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_wandb\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_training_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_training_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[43m    \u001b[49m\u001b[43mall_layers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mall_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwandb_suffix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwandb_suffix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[43m    \u001b[49m\u001b[43msource_model_loss\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msource_model_loss\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    172\u001b[0m mse_losses\u001b[38;5;241m.\u001b[39mappend(step_output\u001b[38;5;241m.\u001b[39mmse_loss)\n\u001b[1;32m    173\u001b[0m l1_losses\u001b[38;5;241m.\u001b[39mappend(step_output\u001b[38;5;241m.\u001b[39ml1_loss)\n",
      "File \u001b[0;32m~/SAELens/sae_lens/training/train_sae_on_language_model.py:443\u001b[0m, in \u001b[0;36m_train_step\u001b[0;34m(sparse_autoencoder, layer_acts, ctx, feature_sampling_window, use_wandb, n_training_steps, all_layers, batch_size, wandb_suffix, source_model_loss)\u001b[0m\n\u001b[1;32m    431\u001b[0m ghost_grad_neuron_mask \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    432\u001b[0m     ctx\u001b[38;5;241m.\u001b[39mn_forward_passes_since_fired \u001b[38;5;241m>\u001b[39m sparse_autoencoder\u001b[38;5;241m.\u001b[39mcfg\u001b[38;5;241m.\u001b[39mdead_feature_window\n\u001b[1;32m    433\u001b[0m )\u001b[38;5;241m.\u001b[39mbool()\n\u001b[1;32m    435\u001b[0m \u001b[38;5;66;03m# Forward and Backward Passes\u001b[39;00m\n\u001b[1;32m    436\u001b[0m (\n\u001b[1;32m    437\u001b[0m     sae_out,\n\u001b[1;32m    438\u001b[0m     feature_acts,\n\u001b[1;32m    439\u001b[0m     loss,\n\u001b[1;32m    440\u001b[0m     mse_loss,\n\u001b[1;32m    441\u001b[0m     l1_loss,\n\u001b[1;32m    442\u001b[0m     ghost_grad_loss,\n\u001b[0;32m--> 443\u001b[0m ) \u001b[38;5;241m=\u001b[39m \u001b[43msparse_autoencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    444\u001b[0m \u001b[43m    \u001b[49m\u001b[43msae_in\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    445\u001b[0m \u001b[43m    \u001b[49m\u001b[43mghost_grad_neuron_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    446\u001b[0m \u001b[43m    \u001b[49m\u001b[43msource_model_loss\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    447\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    448\u001b[0m did_fire \u001b[38;5;241m=\u001b[39m (feature_acts \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39msum(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    449\u001b[0m ctx\u001b[38;5;241m.\u001b[39mn_forward_passes_since_fired \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/SAELens/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/SAELens/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/SAELens/sae_lens/training/sparse_autoencoder.py:199\u001b[0m, in \u001b[0;36mSparseAutoencoder.forward\u001b[0;34m(self, x, dead_neuron_mask, source_model_loss)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;66;03m# add config for whether l2 is normalized:\u001b[39;00m\n\u001b[1;32m    196\u001b[0m per_item_mse_loss \u001b[38;5;241m=\u001b[39m _per_item_mse_loss_with_target_norm(\n\u001b[1;32m    197\u001b[0m     sae_out, x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg\u001b[38;5;241m.\u001b[39mmse_loss_normalization\n\u001b[1;32m    198\u001b[0m )\n\u001b[0;32m--> 199\u001b[0m ghost_grad_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;66;03m# gate on config and training so evals is not slowed down.\u001b[39;00m\n\u001b[1;32m    201\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    202\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_ghost_grads\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining\n\u001b[1;32m    204\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m dead_neuron_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    205\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m dead_neuron_mask\u001b[38;5;241m.\u001b[39msum() \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    206\u001b[0m ):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cfg = LanguageModelSAERunnerConfig(\n",
    "    # Data Generating Function (Model + Training Distibuion)\n",
    "    model_name=\"gpt2-small\",\n",
    "    hook_point=\"blocks.8.hook_resid_pre\",\n",
    "    hook_point_layer=8,\n",
    "    d_in=768,\n",
    "    dataset_path=\"apollo-research/Skylion007-openwebtext-tokenizer-gpt2\",\n",
    "    is_dataset_tokenized=True,\n",
    "    prepend_bos=True,  # should experiment with turning this off.\n",
    "    # SAE Parameters\n",
    "    expansion_factor=32,  # determines the dimension of the SAE.\n",
    "    b_dec_init_method=\"geometric_median\",  # geometric median is better but slower to get started\n",
    "    apply_b_dec_to_input=False,\n",
    "    # Training Parameters\n",
    "    adam_beta1=0,\n",
    "    adam_beta2=0.999,\n",
    "    lr=0.002,\n",
    "    l1_coefficient=0.008,\n",
    "    lr_scheduler_name=\"constant\",\n",
    "    train_batch_size=4096,\n",
    "    context_size=256,\n",
    "    lr_warm_up_steps=5000,\n",
    "    # Activation Store Parameters\n",
    "    n_batches_in_buffer=128,\n",
    "    training_tokens=1_000_000 * 200,  # 200M tokens seems doable overnight.\n",
    "    finetuning_method=\"decoder\",\n",
    "    finetuning_tokens=1_000_000 * 100,\n",
    "    store_batch_size=32,\n",
    "    # Resampling protocol\n",
    "    use_ghost_grads=False,\n",
    "    feature_sampling_window=2500,\n",
    "    dead_feature_window=5000,\n",
    "    dead_feature_threshold=1e-8,\n",
    "    # WANDB\n",
    "    log_to_wandb=True,\n",
    "    wandb_project=\"gpt2_sae_source_model_loss_normalization\",\n",
    "    wandb_entity=None,\n",
    "    wandb_log_frequency=100,\n",
    "    # Misc\n",
    "    device=device,\n",
    "    seed=42,\n",
    "    n_checkpoints=5,\n",
    "    checkpoint_path=\"checkpoints\",\n",
    "    dtype=torch.float32,\n",
    "    # New parameters\n",
    "    normalize_loss_with_source_model_loss=True,\n",
    "    collect_source_model_loss=True,\n",
    ")\n",
    "\n",
    "sparse_autoencoder = language_model_sae_runner(cfg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mats_sae_training",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
